{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b42136-e184-4aa4-b693-d968c4ac3158",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b25c8ec-06e6-4619-933f-f7f8c756ce38",
   "metadata": {},
   "source": [
    "###### Stemming is the process of reducing a word to its to its stem that affixes to suffixes and prefixes or to the roots of words known as lemma. Stemming is important in Natural Language Understanding (NLU), and Natural Language Processing(NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f2e6d-39b5-4984-9a7a-5d60a62c7597",
   "metadata": {},
   "source": [
    "for example : goes, going, gone ----> go , eaten, eating ----> eat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4358531-7a20-4f19-8ae4-aeceafd1107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eating', 'eats', 'eaten', 'writes', 'writing', 'written', 'programming', 'programs', 'history', 'finally', 'finalize']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef7fbd-d8fc-4209-ab5c-0a0573e99aa8",
   "metadata": {},
   "source": [
    "### 1. Porter Stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68c7e09-1afa-4ceb-a30d-2d6600c9b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7152e9-048a-497d-87a4-b912ffa2c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb23fe4-d4fc-4237-8232-cefab282b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating    ---->    eat\n",
      "eats    ---->    eat\n",
      "eaten    ---->    eaten\n",
      "writes    ---->    write\n",
      "writing    ---->    write\n",
      "written    ---->    written\n",
      "programming    ---->    program\n",
      "programs    ---->    program\n",
      "history    ---->    histori\n",
      "finally    ---->    final\n",
      "finalize    ---->    final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"    ---->    \" + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1880018-d72a-4407-8681-fbab3de0209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratul\n"
     ]
    }
   ],
   "source": [
    " print(stemming.stem(\"Congratulations\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b76d14-4f52-4c5c-acb6-39733a680d65",
   "metadata": {},
   "source": [
    "There is a major disadvantage of using porter stemmer for stemming. That disadvantage is that may of the words are changed and not converted to their stems, for example: in above situations eaten is converted to eaten, written is converted to written history to histori, and congratulations to congratul."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1afbc0-5a7b-4f9d-890f-d61045dac4bf",
   "metadata": {},
   "source": [
    "### 2. RegexpStemmer class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a10b26-7f0b-4f57-9c03-eac551bd4f87",
   "metadata": {},
   "source": [
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It actually takes a single regular expression and removes any prefix or suffix that matches the expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e76411e-8004-4084-940b-f9d8d0b75d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bae4beb6-1871-4c83-9521-fe9190c29ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e1947f1-dfe0-4cb9-aa94-bedfbeb3372a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating') ## paas the language that you want to use stemming for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "274dab22-ce44-40a6-8ce2-6bf074c25f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"ingeating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffb5076d-6208-47d6-9044-c90b1d188bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating    ---->    eat\n",
      "eats    ---->    eat\n",
      "eaten    ---->    eaten\n",
      "writes    ---->    write\n",
      "writing    ---->    writ\n",
      "written    ---->    written\n",
      "programming    ---->    programm\n",
      "programs    ---->    program\n",
      "history    ---->    history\n",
      "finally    ---->    finally\n",
      "finalize    ---->    finaliz\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"    ---->    \" + reg_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19f1c2-ec83-46d3-8db8-2e97a7ac56bf",
   "metadata": {},
   "source": [
    "in RegexpStemmer the problem is that the arguements we have passed will be followed only and we can see the results above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e21e0-8c50-4152-b672-6f83bac4deb6",
   "metadata": {},
   "source": [
    "### 3. Snowball Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722a67e-0178-48c0-821b-07b086c4f0ff",
   "metadata": {},
   "source": [
    "It Gives better accuracy when compared with the porter stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fab4597-5287-4706-9382-a0d4041644f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82ae243b-7cfb-48b6-8065-111df6783bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e36d1b1-ffc7-4c76-b1b7-47d99ea4e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating    ---->    eat\n",
      "eats    ---->    eat\n",
      "eaten    ---->    eaten\n",
      "writes    ---->    write\n",
      "writing    ---->    write\n",
      "written    ---->    written\n",
      "programming    ---->    program\n",
      "programs    ---->    program\n",
      "history    ---->    histori\n",
      "finally    ---->    final\n",
      "finalize    ---->    final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"    ---->    \" + snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44fba1-4cbc-4ce5-b7cf-7f6c2ae1f999",
   "metadata": {},
   "source": [
    "###### Comparing porter stemmer and snowball stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99a8a0a7-f76b-4af0-b983-9778196c0bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## with porter stemmer \n",
    "stemming.stem('fairly'), stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b028fc2-5a3f-4ee6-9d34-c8bae80261bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## with Snowball stemmer \n",
    "snow_stemmer.stem('fairly'), snow_stemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976b686-44a2-481f-838c-82236571e69a",
   "metadata": {},
   "source": [
    "we can clearly see that snowball stemmer is fairly performing better than porter stemmer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee4970-2824-4400-b792-31a3381b60cc",
   "metadata": {},
   "source": [
    "###### we can see that there are certain problems that are unsolved in stemming. But these problems can be solved by Lemmatization, which will be covered in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051d208-543e-46fa-8c99-216d041ee4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
