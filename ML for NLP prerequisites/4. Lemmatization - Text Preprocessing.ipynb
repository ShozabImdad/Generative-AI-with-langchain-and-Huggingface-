{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04e5178-aeba-421f-8cc9-1e32cc573eb0",
   "metadata": {},
   "source": [
    "# Wordnet Lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c98fd-afb8-44a6-a221-11efc4e87d4e",
   "metadata": {},
   "source": [
    "Lemmatization technique is like stemming technique. The output we will get after lemmatization will be called 'lemma', which is a root word, rather than the root stem which we get in case of stemming. After performing lemmatization we will get the exact root word which will mean the same as it should be.\n",
    "\n",
    "NLTK provides WordNetLemmetizer() class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet Corpus Reader class to find a lemma.\n",
    "\n",
    "wordnet lemmatizer is more time consuming than stemming, because it uses multiple functionalities as compared to stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "396a3096-c673-4130-8d53-3a622b17110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58234e21-6c2c-4c7c-89db-0318626bcf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\HH\n",
      "[nltk_data]     Traders\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12708b1f-0518-4ef1-80c2-d0cfba2b1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c3ea4b-4e44-4db1-a879-7fd1b6682cc4",
   "metadata": {},
   "source": [
    "lemmatizer.lemmatize(word: str, pos: str = 'n')\n",
    "\n",
    ":param word: The input word to lemmatize.\n",
    "\n",
    ":type word: str\n",
    "\n",
    ":param pos: The Part Of Speech tag. Valid options are `\"n\"` for nouns,\n",
    "    `\"v\"` for verbs, `\"a\"` for adjectives, `\"r\"` for adverbs and `\"s\"`\n",
    "    for satellite adjectives.\n",
    "\n",
    ":type pos: str\n",
    "\n",
    ":return: The shortest lemma of `word`, for the given `pos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adc1e5cb-fd34-4336-a686-71d1b53b804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35e2d356-5a4a-4b70-938f-fc7a0287b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eating', 'eats', 'eaten', 'writes', 'writing', 'written', 'programming', 'programs', 'history', 'finally', 'finalize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0385f0f-7864-4c3e-b0c1-2d19a295e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating    ---->    eat\n",
      "eats    ---->    eat\n",
      "eaten    ---->    eat\n",
      "writes    ---->    write\n",
      "writing    ---->    write\n",
      "written    ---->    write\n",
      "programming    ---->    program\n",
      "programs    ---->    program\n",
      "history    ---->    history\n",
      "finally    ---->    finally\n",
      "finalize    ---->    finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"    ---->    \" + lemmatizer.lemmatize(word,  pos = 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a085215-76d2-4050-9cc6-54787c9aca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'sportingly')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('fairly', pos = 'r'), lemmatizer.lemmatize(\"sportingly\", pos = 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ae6cd-e2bc-4491-8eea-b547f9bae827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6c902-834d-405f-907b-d8a72d769e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
